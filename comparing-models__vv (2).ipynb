{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework - Comparing Models\n",
    "Run the following code and then answer the numbered questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_company</th>\n",
       "      <th>age</th>\n",
       "      <th>frequency_of_travel</th>\n",
       "      <th>department</th>\n",
       "      <th>commuting_distance</th>\n",
       "      <th>education</th>\n",
       "      <th>satisfaction_with_environment</th>\n",
       "      <th>gender</th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>position</th>\n",
       "      <th>satisfaction_with_job</th>\n",
       "      <th>married_or_single</th>\n",
       "      <th>last_raise_pct</th>\n",
       "      <th>last_performance_rating</th>\n",
       "      <th>total_years_working</th>\n",
       "      <th>years_at_company</th>\n",
       "      <th>years_in_current_job</th>\n",
       "      <th>years_since_last_promotion</th>\n",
       "      <th>years_with_current_supervisor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>37</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Sales</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>Sales Executive</td>\n",
       "      <td>3</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>39</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>Laboratory Technician</td>\n",
       "      <td>3</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>52</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>4</td>\n",
       "      <td>Manufacturing Director</td>\n",
       "      <td>4</td>\n",
       "      <td>Married</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>50</td>\n",
       "      <td>Non-Travel</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>Sales Executive</td>\n",
       "      <td>3</td>\n",
       "      <td>Married</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>44</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>Healthcare Representative</td>\n",
       "      <td>2</td>\n",
       "      <td>Single</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  left_company  age frequency_of_travel              department  \\\n",
       "0           No   37       Travel_Rarely                   Sales   \n",
       "1           No   39       Travel_Rarely  Research & Development   \n",
       "2           No   52   Travel_Frequently  Research & Development   \n",
       "3           No   50          Non-Travel                   Sales   \n",
       "4           No   44       Travel_Rarely  Research & Development   \n",
       "\n",
       "   commuting_distance  education  satisfaction_with_environment  gender  \\\n",
       "0                  16          4                              4    Male   \n",
       "1                   3          2                              3    Male   \n",
       "2                  25          4                              3  Female   \n",
       "3                   1          3                              4  Female   \n",
       "4                   4          3                              4    Male   \n",
       "\n",
       "   seniority_level                   position  satisfaction_with_job  \\\n",
       "0                2            Sales Executive                      3   \n",
       "1                2      Laboratory Technician                      3   \n",
       "2                4     Manufacturing Director                      4   \n",
       "3                2            Sales Executive                      3   \n",
       "4                2  Healthcare Representative                      2   \n",
       "\n",
       "  married_or_single  last_raise_pct  last_performance_rating  \\\n",
       "0          Divorced              19                        3   \n",
       "1          Divorced              15                        3   \n",
       "2           Married              22                        4   \n",
       "3           Married              12                        3   \n",
       "4            Single              12                        3   \n",
       "\n",
       "   total_years_working  years_at_company  years_in_current_job  \\\n",
       "0                    9                 1                     0   \n",
       "1                   11                10                     8   \n",
       "2                   31                 9                     8   \n",
       "3                   19                18                     7   \n",
       "4                   10                 5                     2   \n",
       "\n",
       "   years_since_last_promotion  years_with_current_supervisor  \n",
       "0                           0                              0  \n",
       "1                           0                              7  \n",
       "2                           0                              0  \n",
       "3                           0                             13  \n",
       "4                           2                              3  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "df = pd.read_csv('employee-turnover-balanced.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 19 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   left_company                   1000 non-null   object\n",
      " 1   age                            1000 non-null   int64 \n",
      " 2   frequency_of_travel            1000 non-null   object\n",
      " 3   department                     1000 non-null   object\n",
      " 4   commuting_distance             1000 non-null   int64 \n",
      " 5   education                      1000 non-null   int64 \n",
      " 6   satisfaction_with_environment  1000 non-null   int64 \n",
      " 7   gender                         1000 non-null   object\n",
      " 8   seniority_level                1000 non-null   int64 \n",
      " 9   position                       1000 non-null   object\n",
      " 10  satisfaction_with_job          1000 non-null   int64 \n",
      " 11  married_or_single              1000 non-null   object\n",
      " 12  last_raise_pct                 1000 non-null   int64 \n",
      " 13  last_performance_rating        1000 non-null   int64 \n",
      " 14  total_years_working            1000 non-null   int64 \n",
      " 15  years_at_company               1000 non-null   int64 \n",
      " 16  years_in_current_job           1000 non-null   int64 \n",
      " 17  years_since_last_promotion     1000 non-null   int64 \n",
      " 18  years_with_current_supervisor  1000 non-null   int64 \n",
      "dtypes: int64(13), object(6)\n",
      "memory usage: 148.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: left_company\n",
      "Features:\n",
      "age,\tfrequency_of_travel,\tdepartment,\tcommuting_distance,\teducation,\tsatisfaction_with_environment,\tgender,\tseniority_level,\tposition,\tsatisfaction_with_job,\tmarried_or_single,\tlast_raise_pct,\tlast_performance_rating,\ttotal_years_working,\tyears_at_company,\tyears_in_current_job,\tyears_since_last_promotion,\tyears_with_current_supervisor\n",
      "\n",
      "\n",
      "Training examples: 800\n",
      "Test examples: 200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "targetCol = 'left_company'\n",
    "featureCols = [x for x in df.columns if x != targetCol]\n",
    "\n",
    "y = df[targetCol]\n",
    "X = df[featureCols]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 123)\n",
    "\n",
    "print(f'Target: {targetCol}')\n",
    "print('Features:')\n",
    "print(*featureCols, sep=',\\t')\n",
    "print('\\n')\n",
    "print(f'Training examples: {x_train.shape[0]:,}')\n",
    "print(f'Test examples: {x_test.shape[0]:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "- Set-up a feature processing pipeline using the training data.  \n",
    "- While the data doesn't contain missing values, assume the test data could.  \n",
    "- Use the below lists to split the features that should be treated as numerical and categorical variables.  \n",
    "- I would recommend printing out verification output to verify the pipeline transforms the data as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericalFeatures = ['age', 'commuting_distance', 'last_raise_pct', 'total_years_working', 'years_at_company',\n",
    "                    'years_in_current_job', 'years_since_last_promotion', 'years_with_current_supervisor']\n",
    "\n",
    "categoricalFeatures = ['frequency_of_travel', 'department', 'education', 'satisfaction_with_environment',\n",
    "                       'gender', 'seniority_level', 'position', 'satisfaction_with_job', 'married_or_single',\n",
    "                      'last_performance_rating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No missing  Values in dataset \n",
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    500\n",
       "Name: left_company, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Balenced Dataset \n",
    "y.replace(['Yes','No'],[1,0], inplace=True)\n",
    "y.hist(bins =10, figsize=(15,6));\n",
    "\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pipeline that replaces the missing values with the median and then standardizes the values using a standard scaler for Numerical variables\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import MissingIndicator\n",
    "\n",
    "pp_num = Pipeline([\n",
    "    ('num_imp', SimpleImputer(strategy='median', add_indicator=False)),\n",
    "    #('rob_num',StandardScaler())\n",
    "])\n",
    "\n",
    "ct_Numerical = ColumnTransformer([\n",
    "    ('mi', MissingIndicator(), X.columns),\n",
    "    ('pp_num', pp_num, numericalFeatures)\n",
    "])\n",
    "\n",
    "\n",
    "#pipeline that replaces the missing values with the median and then standardizes the values using a standard scaler for categorical variables\n",
    "pp_cat = Pipeline([\n",
    "    ('cat_imp', SimpleImputer(strategy='most_frequent', add_indicator=False, fill_value='missing')),\n",
    "    ('ohe_cat', OneHotEncoder(sparse=False, handle_unknown='error',drop='if_binary'))\n",
    "])\n",
    "\n",
    "\n",
    "ct_catogirical = ColumnTransformer([\n",
    "    ('mi', MissingIndicator(), X.columns),\n",
    "    ('pp_cat', pp_cat, categoricalFeatures)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical train  Data Shape: (800, 8)\n",
      "Catogirical train  Data Shape: (800, 38)\n"
     ]
    }
   ],
   "source": [
    "Numerical_train= ct_Numerical.fit_transform(x_train).astype(np.float)\n",
    "Catogirical_train= ct_catogirical.fit_transform(x_train).astype(np.float)\n",
    "print('Numerical train  Data Shape:',Numerical_train.shape)\n",
    "print('Catogirical train  Data Shape:',Catogirical_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both Numerical and Categorical \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import MissingIndicator\n",
    "ct = ColumnTransformer([\n",
    "    ('mi', MissingIndicator(), X.columns),\n",
    "    ('pp_num', pp_num, numericalFeatures),\n",
    "    ('pp_cat', pp_cat, categoricalFeatures)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4    5    6    7    8    9   ...   36   37   38  \\\n",
       "0  33.0  10.0  13.0   8.0   4.0  3.0  1.0  3.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1  23.0   9.0  19.0   1.0   1.0  0.0  1.0  0.0  0.0  1.0  ...  0.0  1.0  1.0   \n",
       "2  18.0   5.0  14.0   0.0   0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  1.0  0.0   \n",
       "3  31.0   1.0  11.0  10.0  10.0  8.0  4.0  7.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
       "4  29.0   6.0  13.0  10.0  10.0  8.0  0.0  8.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "    39   40   41   42   43   44   45  \n",
       "0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "2  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "3  1.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "4  0.0  0.0  1.0  0.0  1.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain= ct.fit_transform(x_train).astype(np.float)\n",
    "pd.DataFrame(xtrain).head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 46)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest=ct.transform(x_test).astype(np.float)\n",
    "xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference:\n",
    "Here we are splitting data based on given criteria\n",
    "insted of One-Hot encoding we can convert below  features based on frequency/Count using replace/get_dummies\n",
    "it will reduce the Dimension and Sparcity \n",
    "\n",
    "Features: \n",
    "frequency_of_travel{'Travel_Frequently', 'Non-Travel', 'Travel_Rarely'} and Count3\n",
    "department{'Research & Development', 'Sales', 'Human Resources'} and Count3\n",
    "gender{'Male', 'Female'} and Count2\n",
    "married_or_single{'Divorced', 'Married', 'Single'} and Count3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "- Using cross-validation evaluate a logistic regression model, evaluate three (4) different regularization strengths with `l2`, with one model containing no regularization.  \n",
    "- Which regularization strength would be ideal for logistic regression?\n",
    "- Use as much code as you need to defend your opinion.  \n",
    "- Comment on your rationale for your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7300000000000001"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LogisticRegression with No Regularization \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "pipe_final = Pipeline([\n",
    "    ('ct_step', ct),\n",
    "    ('model', model )\n",
    "])\n",
    "\n",
    "pipe_final_n=pipe_final.fit(x_train,y_train)\n",
    "scores=cross_val_score(pipe_final_n,x_test,y_test,cv=10)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.695"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression with L2 Regularization and C=100:\n",
    "model1 = LogisticRegression(C=100,penalty='l2' )\n",
    "\n",
    "pipe_final1 = Pipeline([\n",
    "    ('ct_step', ct),\n",
    "    ('model', model1 )\n",
    "])\n",
    "\n",
    "pipe_final_n1=pipe_final1.fit(x_train,y_train)\n",
    "scores1=cross_val_score(pipe_final_n1,x_test,y_test,cv=10)\n",
    "scores1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7300000000000001"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression with L2 Regularization and C=1:\n",
    "model2 = LogisticRegression(C=1,penalty='l2' )\n",
    "\n",
    "pipe_final2 = Pipeline([\n",
    "    ('ct_step', ct),\n",
    "    ('model', model2 )\n",
    "])\n",
    "pipe_final_n2=pipe_final2.fit(x_train,y_train)\n",
    "scores2=cross_val_score(pipe_final_n2,x_test,y_test,cv=10)\n",
    "scores2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression with L2 Regularization and C=0.1:\n",
    "model3 = LogisticRegression(C=0.1,penalty='l2' )\n",
    "\n",
    "pipe_final3 = Pipeline([\n",
    "    ('ct_step', ct),\n",
    "    ('model', model3 )\n",
    "])\n",
    "\n",
    "pipe_final_n3=pipe_final3.fit(x_train,y_train)\n",
    "scores3=cross_val_score(pipe_final_n3,x_test,y_test,cv=10)\n",
    "scores3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6799999999999999"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression with L2 Regularization and C=0.1:\n",
    "model4 = LogisticRegression(C=0.01,penalty='l2' )\n",
    "\n",
    "pipe_final4 = Pipeline([\n",
    "    ('ct_step', ct),\n",
    "    ('model', model4 )\n",
    "])\n",
    "pipe_final_n4=pipe_final4.fit(x_train,y_train)\n",
    "scores4=cross_val_score(pipe_final_n4,x_test,y_test,cv=10)\n",
    "scores4.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6300000000000001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression with L2 Regularization and C=0.001:\n",
    "model5 = LogisticRegression(C=0.001,penalty='l2' )\n",
    "\n",
    "pipe_final5 = Pipeline([\n",
    "    ('ct_step', ct),\n",
    "    ('model', model5 )\n",
    "])\n",
    "pipe_final_n5=pipe_final5.fit(x_train,y_train)\n",
    "scores5=cross_val_score(pipe_final_n5,x_test,y_test,cv=10)\n",
    "scores5.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with No Regularization: 0.7300000000000001\n",
      "Logistic Regression with L2 Regularization and C=100: 0.695\n",
      "Logistic Regression with L2 Regularization and C=1: 0.7300000000000001\n",
      "Logistic Regression with L2 Regularization and C=0.1: 0.72\n",
      "Logistic Regression with L2 Regularization and C=0.01: 0.6799999999999999\n",
      "Logistic Regression with L2 Regularization and C=0.001: 0.6300000000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression with No Regularization:\",scores.mean())\n",
    "print(\"Logistic Regression with L2 Regularization and C=100:\",scores1.mean())\n",
    "print(\"Logistic Regression with L2 Regularization and C=1:\",scores2.mean())\n",
    "print(\"Logistic Regression with L2 Regularization and C=0.1:\",scores3.mean())\n",
    "print(\"Logistic Regression with L2 Regularization and C=0.01:\",scores4.mean())\n",
    "print(\"Logistic Regression with L2 Regularization and C=0.001:\",scores5.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Inference:\n",
    "Which regularization strength would be ideal for logistic regression?\n",
    "\n",
    "Logistic Regression with No Regularization: 0.7300000000000001\n",
    "and Logistic Regression with L2 Regularization and C=1: 0.7300000000000001 \n",
    "will same kind of accuracy on Test data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "- Using cross-validation, evaluate a decision tree. Consider at least 3 different `max_depth` and 3 different `min_samples_split`. Use a fraction for the `min_samples_split`.  \n",
    "- Which combination seems to be the ideal for the decision tree? Use performance from the cross-validation and test sets to defend your opinion.  \n",
    "- Use as much code a you need to defend your opinion.  \n",
    "- Comment on your rationale for your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7300000000000001\n"
     ]
    }
   ],
   "source": [
    "# insert code here\n",
    "# Decision Tree with max_depth = 4 , min_samples_split= 0.1\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "DT = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4 , min_samples_split= 0.1)\n",
    "\n",
    "pipe_final_DT = Pipeline([\n",
    "    ('ct_step', ct),\n",
    "    ('model', DT )\n",
    "])\n",
    "\n",
    "pipe_final_DT_0=pipe_final_DT.fit(x_train,y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scoresDT=cross_val_score(pipe_final_DT_0,x_test, y_test,cv=10)\n",
    "print(scoresDT.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6700000000000002\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree with max_depth = 6 , min_samples_split= 0.01\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "DT1 = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 6 , min_samples_split= 0.01)\n",
    "\n",
    "pipe_final_DT1 = Pipeline([\n",
    "    ('ct_step', ct),\n",
    "    ('model', DT1 )\n",
    "])\n",
    "\n",
    "pipe_final_DT_1=pipe_final_DT1.fit(x_train,y_train)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scoresDT1=cross_val_score(pipe_final_DT_1,x_test, y_test,cv=10)\n",
    "print(scoresDT1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6849999999999999\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree with max_depth = 8 , min_samples_split= 0.001\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "DT2 = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 8 , min_samples_split= 0.001)\n",
    "\n",
    "pipe_final_DT2 = Pipeline([\n",
    "    ('ct_step', ct),\n",
    "    ('model', DT2 )\n",
    "])\n",
    "pipe_final_DT_2=pipe_final_DT2.fit(x_train,y_train)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scoresDT2=cross_val_score(pipe_final_DT_2,x_test, y_test,cv=10)\n",
    "print(scoresDT2.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Inference:\n",
    "\n",
    "Below Combination gives best accuracy score then compare to another combinations \n",
    "\n",
    "DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4 , min_samples_split= 0.1)\n",
    "\n",
    "If Deapth of the Decistion tree increases it will lead to Overfitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "- Compare the best logistic regression and best decision tree and decide which is superior.  \n",
    "- Use as much code as you need to defend your opinion. Use performance from the cross-validation and test sets to defend your opinion.  \n",
    "- Comment on your rationale for your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with No Regularization: 0.7300000000000001\n",
      "DecisionTree with max_depth = 4 , min_samples_split= 0.1: 0.7300000000000001\n"
     ]
    }
   ],
   "source": [
    "# Best Models from  logistic regression and best Decision tree\n",
    "print(\"Logistic Regression with No Regularization:\",scores.mean())\n",
    "print(\"DecisionTree with max_depth = 4 , min_samples_split= 0.1:\",scoresDT.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Inference:\n",
    "\n",
    "Based on above 2 classifications models giving same kind of accuracy scores based on Cross validation on Test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
